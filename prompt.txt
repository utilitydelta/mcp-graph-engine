Okay, so today what I'm thinking is I want to build an MCP server that I can use with  Cloud Code.  What I'm interested in is a graph    
  engine.  So think of it like this, the LLM is picking up all this information as it goes working  around say a code base or when it's    
  doing research.  You can use the MCP server to add nodes and form edges between nodes.  Then it can use the MCP server to run algorithms 
  like shortest path, transitive reduction, page rank, etc. The interesting part is that it can just be transient in memory store, And it  
  just has to be simple, like a really simple interface for the LLM to use. The other thing I'm thinking of is typically when we work      
  programmatically with graph data structures  there's a lot of use of  IDs whether it be  just  monotonically increasing  indexes or a    
  UUID or a  Nanoid  but I'm not sure if LLMs would be good at that and maybe  instead what we should do is  match  nodes and edges and    
  relationships in a fuzzy way kind of like a vector search to make it easier for LLMs to  Build relationships while it's thinking. I'm    
  interested to hear your thoughts.  Also, I think the MCP server needs to be able to handle multiple concurrent graphs in use,  because   
  often users are running more than one Cloud Code instance on a single PC. I'm thinking under the hood we use NetworkX or GRAPE           
  (https://github.com/AnacletoLAB/grape). Another idea I had is a lot of these graph libraries that they support import from known graph   
  formats.  And the LLM will probably know how to create a .file, for example.  So instead of working with the MCP, you know, add node,    
  add edge, it can just create a .file and then just throw that file to the MCP to create like a new graph session essentially. I've       
  cloned down the grape library into the grape folder, take a look at it and see what  we can build with MCP using grape.  Let's build a   
  design document that I can review before we kick off the building of the MCP server. In the design document, let's not just talk about   
  what we're going to build, but also the why.  So at the start, we'll talk about some of the problems and why a graph engine would be     
  helpful for a LLM while it's working,  how it could be used, its benefits, you know, all that kind of stuff. 
